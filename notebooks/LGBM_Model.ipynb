{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1uuk3HeL9UF88Ii4tOKD69R9sPKar8L6v","authorship_tag":"ABX9TyNtxhvPVMRl/E7vnmXLmS9x"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"1ZCBaJ_UNoDi"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","# import tensorflow_addons as tfa # --- REMOVED: Package is deprecated ---\n","import itertools\n","import shutil\n","from PIL import Image\n","\n","# --- ML/Preprocessing Imports ---\n","from sklearn.metrics import (\n","    confusion_matrix,\n","    accuracy_score,\n","    classification_report,\n",")\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.utils import resample\n","from sklearn.impute import SimpleImputer\n","\n","# --- Keras Imports ---\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.applications import EfficientNetB3\n","# --- Import preprocess_input ---\n","from keras.applications.efficientnet import preprocess_input\n","from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n","from keras.layers import (\n","    Input, Dense, Dropout, BatchNormalization, Concatenate,\n","    RandomRotation # --- FIX: Added RandomRotation import ---\n",")\n","from google.colab import drive\n","\n","# --- 0. Mount Google Drive (with check) ---\n","print(\"Mounting Google Drive...\")\n","if not os.path.isdir('/content/drive'):\n","    drive.mount('/content/drive')\n","else:\n","    print(\"Google Drive already mounted.\")\n","\n","# --- 1. Constants and Setup ---\n","# ðŸ”” IMPORTANT: Update this path to your archive.zip on Drive!\n","ARCHIVE_PATH_ON_DRIVE = '/content/drive/MyDrive/archive.zip'\n","\n","# Path to extract to on the local Colab runtime\n","EXTRACT_PATH = '/content/dataset'\n","\n","# --- Define save paths ---\n","MODEL_SAVE_DIR = '/content/drive/MyDrive/kaggle/working'\n","STAGE_1_SAVE_PATH = os.path.join(MODEL_SAVE_DIR, 'skin_hybrid_stage_1.keras')\n","FINAL_SAVE_PATH = os.path.join(MODEL_SAVE_DIR, 'skin_hybrid_final_model.keras')\n","\n","os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n","\n","# --- 1b. Unzip Data to Local Disk (FAST I/O) ---\n","if not os.path.isdir(EXTRACT_PATH):\n","    print(f\"Extracting {ARCHIVE_PATH_ON_DRIVE} to local runtime at {EXTRACT_PATH}...\")\n","    print(\"This may take 5-10 minutes, but will make training much faster.\")\n","    os.makedirs(EXTRACT_PATH, exist_ok=True)\n","    shutil.unpack_archive(ARCHIVE_PATH_ON_DRIVE, EXTRACT_PATH)\n","    print(\"âœ… Extraction complete.\")\n","else:\n","    print(f\"âœ… Dataset already extracted at {EXTRACT_PATH}.\")\n","\n","\n","# --- 1c. Update All Paths to Use Local Data ---\n","DATA_ROOT = EXTRACT_PATH\n","METADATA_CSV_PATH = os.path.join(DATA_ROOT, 'ISIC_2019_Training_Metadata.csv')\n","GROUND_TRUTH_CSV_PATH = os.path.join(DATA_ROOT, 'ISIC_2019_Training_GroundTruth.csv')\n","\n","print(f\"Data root set to: {DATA_ROOT}\")\n","print(f\"Stage 1 Model will be saved to: {STAGE_1_SAVE_PATH}\")\n","print(f\"Final Model will be saved to: {FINAL_SAVE_PATH}\")\n","\n","# Model parameters\n","IMG_SIZE = (256, 256)\n","BATCH_SIZE = 32\n","AUTOTUNE = tf.data.AUTOTUNE\n","SEED = 123\n","# --- Target number of samples per class for balancing ---\n","TARGET_SAMPLES = 4000\n","# --- NEW: Rotation factor converted from radians (0.21) to 2*pi fraction ---\n","ROTATION_FACTOR = 0.21 / (2 * np.pi) # approx 0.0334\n","\n","# --- 2. CutMix Utility Functions ---\n","print(\"\\nLoading CutMix utility functions...\")\n","\n","def sample_beta_distribution(size, concentration=0.2):\n","    gamma1 = tf.random.gamma(shape=[size], alpha=concentration, beta=1.0)\n","    gamma2 = tf.random.gamma(shape=[size], alpha=concentration, beta=1.0)\n","    return gamma1 / (gamma1 + gamma2)\n","\n","# --- Fully vectorized cutmix function (removes for loops) ---\n","def cutmix(image, label, PROBABILITY=0.8):\n","    do_cutmix = tf.random.uniform([], 0, 1)\n","    if do_cutmix > PROBABILITY:\n","        return image, label\n","\n","    H_int = tf.shape(image)[1]\n","    W_int = tf.shape(image)[2]\n","    H = tf.cast(H_int, tf.float32)\n","    W = tf.cast(W_int, tf.float32)\n","\n","    indices = tf.random.shuffle(tf.range(tf.shape(image)[0]))\n","    shuffled_image = tf.gather(image, indices, axis=0)\n","    shuffled_label = tf.gather(label, indices, axis=0)\n","\n","    lam_batch = sample_beta_distribution(tf.shape(image)[0])\n","    lam_batch = tf.cast(lam_batch, dtype=tf.float32)\n","\n","    r_x = tf.cast(tf.random.uniform([tf.shape(image)[0]], 0, W), tf.int32)\n","    r_y = tf.cast(tf.random.uniform([tf.shape(image)[0]], 0, H), tf.int32)\n","\n","    r_w = tf.cast(W * tf.sqrt(1. - lam_batch), tf.int32)\n","    r_h = tf.cast(H * tf.sqrt(1. - lam_batch), tf.int32)\n","\n","    x1 = tf.clip_by_value(r_x - r_w // 2, 0, W_int)\n","    y1 = tf.clip_by_value(r_y - r_h // 2, 0, H_int)\n","    x2 = tf.clip_by_value(r_x + r_w // 2, 0, W_int)\n","    y2 = tf.clip_by_value(r_y + r_h // 2, 0, H_int)\n","\n","    grid_y = tf.range(H_int)[None, :, None, None]\n","    grid_x = tf.range(W_int)[None, None, :, None]\n","    y1_b = y1[:, None, None, None]\n","    y2_b = y2[:, None, None, None]\n","    x1_b = x1[:, None, None, None]\n","    x2_b = x2[:, None, None, None]\n","\n","    mask_y = (grid_y >= y1_b) & (grid_y < y2_b)\n","    mask_x = (grid_x >= x1_b) & (grid_x < x2_b)\n","    mask = tf.cast(mask_y & mask_x, tf.float32)\n","\n","    image = (1. - mask) * image + mask * shuffled_image\n","\n","    lam = 1. - (tf.cast((x2-x1) * (y2-y1), tf.float32) / (H * W))\n","    lam = tf.expand_dims(lam, axis=1)\n","    label = lam * label + (1. - lam) * shuffled_label\n","\n","    return image, label\n","\n","# --- 3. Load and Preprocess Hybrid Data ---\n","print(\"\\nLoading and preprocessing hybrid data (CSV + Images)...\")\n","\n","# Load CSVs\n","df_meta = pd.read_csv(METADATA_CSV_PATH)\n","df_truth = pd.read_csv(GROUND_TRUTH_CSV_PATH)\n","\n","# --- UPDATED: We will remove 'UNK' from this list ---\n","class_names = [col for col in df_truth.columns if col not in ['image', 'UNK']]\n","num_classes = len(class_names)\n","print(f\"Found 8 classes (after removing UNK): {class_names}\")\n","\n","# Convert one-hot truth to sparse labels\n","df_truth['class_name'] = df_truth[class_names + ['UNK']].idxmax(axis=1)\n","\n","# Merge metadata and ground truth\n","df_master = pd.merge(df_meta, df_truth[['image', 'class_name'] + class_names], on='image')\n","\n","# --- NEW: Remove the 'UNK' class as requested ---\n","df_master = df_master[df_master['class_name'] != 'UNK'].reset_index(drop=True)\n","print(f\"Removed 'UNK' class. Remaining samples: {len(df_master)}\")\n","\n","# --- 3a. Create Image Paths ---\n","def get_image_path(row):\n","    return os.path.join(DATA_ROOT, row['class_name'], row['image'] + '.jpg')\n","df_master['image_path'] = df_master.apply(get_image_path, axis=1)\n","\n","# --- 3b. Sanity Checks (as requested) ---\n","print(\"\\n--- Sanity Checks ---\")\n","print(\"Checking metadata paths (adds no time):\")\n","print(df_master[['image_path', 'class_name']].head())\n","\n","print(\"\\nChecking first image load (adds no time):\")\n","try:\n","    test_image_path = df_master['image_path'].iloc[0]\n","    Image.open(test_image_path)\n","    print(f\"âœ… Successfully loaded test image: {test_image_path}\")\n","except Exception as e:\n","    print(f\"âŒ FAILED to load test image: {e}\")\n","    print(\"Please check your ARCHIVE_PATH, DATA_ROOT, and image_path logic.\")\n","print(\"--- End of Sanity Checks ---\")\n","\n","# --- 3c. Preprocess Metadata ---\n","print(\"\\nPreprocessing metadata (Imputing, Scaling, One-Hot)...\")\n","numeric_cols = ['age_approx']\n","categorical_cols = ['sex', 'anatom_site_general']\n","\n","# Handle Missing Values\n","age_imputer = SimpleImputer(strategy='median')\n","df_master['age_approx'] = age_imputer.fit_transform(df_master[['age_approx']]).ravel()\n","for col in categorical_cols:\n","    cat_imputer = SimpleImputer(strategy='most_frequent')\n","    df_master[col] = cat_imputer.fit_transform(df_master[[col]]).ravel()\n","\n","# Scale Numerical Data\n","scaler = StandardScaler()\n","df_master[numeric_cols] = scaler.fit_transform(df_master[numeric_cols])\n","\n","# One-Hot Encode Categorical Data\n","encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n","encoded_cats = encoder.fit_transform(df_master[categorical_cols])\n","meta_features = np.concatenate([df_master[numeric_cols].values, encoded_cats], axis=1)\n","num_meta_features = meta_features.shape[1]\n","print(f\"Created {num_meta_features} metadata features.\")\n","\n","# --- 4. Manually Balance Dataset (Over/Under-sampling) ---\n","print(f\"\\nBalancing dataset to {TARGET_SAMPLES} samples per class...\")\n","\n","balanced_dfs = []\n","for class_name in class_names: # Use the 8-class list\n","    df_class = df_master[df_master['class_name'] == class_name]\n","\n","    should_replace = len(df_class) < TARGET_SAMPLES\n","\n","    df_balanced_class = resample(df_class,\n","                                 replace=should_replace,\n","                                 n_samples=TARGET_SAMPLES,\n","                                 random_state=SEED)\n","    balanced_dfs.append(df_balanced_class)\n","\n","# Concatenate all balanced dataframes\n","df_balanced = pd.concat(balanced_dfs)\n","\n","# Shuffle the final balanced dataframe\n","df_balanced = df_balanced.sample(frac=1, random_state=SEED).reset_index(drop=True)\n","\n","print(f\"Balancing complete. New dataset size: {len(df_balanced)} samples ({num_classes} classes x {TARGET_SAMPLES})\")\n","print(df_balanced['class_name'].value_counts())\n","\n","# --- 5. Prepare Data for Splitting ---\n","# --- Use the new df_balanced from now on ---\n","\n","# --- 5a. Prepare Labels ---\n","from sklearn.preprocessing import LabelEncoder\n","label_encoder = LabelEncoder()\n","# Fit on the balanced classes\n","labels_sparse = label_encoder.fit_transform(df_balanced['class_name'])\n","labels_one_hot = tf.keras.utils.to_categorical(labels_sparse, num_classes=num_classes)\n","\n","# --- 5b. Prepare Metadata ---\n","# Re-extract the correct metadata rows from df_balanced\n","meta_features_balanced = np.concatenate([\n","    df_balanced[numeric_cols].values,\n","    encoder.transform(df_balanced[categorical_cols]) # Use transform, not fit_transform\n","], axis=1)\n","all_meta = meta_features_balanced.astype(np.float32)\n","all_paths = df_balanced['image_path'].values\n","\n","# --- 5c. Create Train/Val/Test Splits ---\n","print(\"Splitting BALANCED data into Train, Validation, and Test sets...\")\n","all_labels_one_hot = labels_one_hot.astype(np.float32)\n","\n","# First split: 70% train, 30% temp\n","train_paths, temp_paths, train_meta, temp_meta, train_labels, temp_labels, train_labels_sparse, temp_labels_sparse = train_test_split(\n","    all_paths, all_meta, all_labels_one_hot, labels_sparse,\n","    test_size=0.3, random_state=SEED, stratify=labels_sparse\n",")\n","# Second split: 15% val, 15% test\n","# --- FIX: Added temp_labels_sparse as an input to be split ---\n","val_paths, test_paths, val_meta, test_meta, val_labels, test_labels, val_labels_sparse, test_labels_sparse = train_test_split(\n","    temp_paths, temp_meta, temp_labels, temp_labels_sparse,\n","    test_size=0.5, random_state=SEED, stratify=temp_labels_sparse\n",")\n","\n","print(f\"Training samples:   {len(train_paths)}\")\n","print(f\"Validation samples: {len(val_paths)}\")\n","print(f\"Test samples:       {len(test_paths)}\")\n","\n","\n","# --- 6. Create tf.data.Dataset Pipeline ---\n","print(\"\\nBuilding tf.data pipelines...\")\n","\n","# --- NEW: Instantiate Keras rotation layer ONCE outside the map function ---\n","rotation_layer = RandomRotation(factor=ROTATION_FACTOR, interpolation='bilinear')\n","\n","# --- Optimized Augmentation Function ---\n","def optimized_augment(image):\n","    # 1. Random horizontal + vertical flip (safe for lesions)\n","    image = tf.image.random_flip_left_right(image)\n","    image = tf.image.random_flip_up_down(image)\n","\n","    # 2. Small random rotation (â‰¤ 12 degrees, safe)\n","    # --- FIX: Replaced tfa.image.rotate with the Keras layer ---\n","    image = rotation_layer(image, training=True)\n","\n","    # 3. Very light zoom (keeps lesion visible and centered)\n","    scales = tf.random.uniform([], 0.95, 1.05)\n","    new_h = tf.cast(scales * tf.cast(tf.shape(image)[0], tf.float32), tf.int32)\n","    new_w = tf.cast(scales * tf.cast(tf.shape(image)[1], tf.float32), tf.int32)\n","    image = tf.image.resize(image, [new_h, new_w])\n","    image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE[0], IMG_SIZE[1])\n","\n","    # 4. Light brightness & contrast adjustments (does not distort lesion color pattern)\n","    image = tf.image.random_brightness(image, max_delta=0.08)\n","    image = tf.image.random_contrast(image, 0.90, 1.10)\n","\n","    return image\n","\n","# --- FIX: Updated load_image_and_meta function to accept (inputs, label) ---\n","def load_image_and_meta(inputs, label, training=True):\n","    path, meta_features = inputs # Unpack the inputs tuple\n","\n","    # Load image from the LOCAL path (fast)\n","    image = tf.io.read_file(path)\n","    try:\n","        image = tf.image.decode_jpeg(image, channels=3)\n","    except tf.errors.InvalidArgumentError: # Corrected exception handling\n","        image = tf.image.decode_png(image, channels=3)\n","\n","    image = tf.image.resize(image, [IMG_SIZE[0], IMG_SIZE[1]])\n","\n","    # âœ… Apply augmentation for training only\n","    if training:\n","        image = optimized_augment(image)\n","\n","    return (image, meta_features), label\n","\n","def apply_cutmix_to_hybrid_batch(inputs, label):\n","    image, meta = inputs\n","    mixed_image, mixed_label = cutmix(image, label) # Uses your function\n","    return (mixed_image, meta), mixed_label\n","\n","# --- Helper function to apply EfficientNet preprocessing ---\n","def preprocess_for_model(inputs, label):\n","    image, meta = inputs\n","    image = preprocess_input(image) # Apply EfficientNet normalization\n","    return (image, meta), label\n","\n","# --- FIX: Updated Train Dataset Pipeline ---\n","train_ds = (\n","    # --- Explicitly define (inputs, outputs) structure ---\n","    tf.data.Dataset.from_tensor_slices(((train_paths, train_meta), train_labels))\n","    .shuffle(len(train_paths))\n","    # --- Update lambda to match new (inputs, label) structure ---\n","    .map(lambda inputs, label: load_image_and_meta(inputs, label, training=True), num_parallel_calls=AUTOTUNE) # training=True\n","    .batch(BATCH_SIZE)\n","    .map(apply_cutmix_to_hybrid_batch, num_parallel_calls=AUTOTUNE)   # CutMix after augmentation\n","    .map(preprocess_for_model, num_parallel_calls=AUTOTUNE) # Apply preprocessing\n","    .prefetch(AUTOTUNE)\n",")\n","\n","# --- FIX: Updated Validation Dataset Pipeline ---\n","val_ds = (\n","    # --- Explicitly define (inputs, outputs) structure ---\n","    tf.data.Dataset.from_tensor_slices(((val_paths, val_meta), val_labels))\n","    # --- Update lambda to match new (inputs, label) structure ---\n","    .map(lambda inputs, label: load_image_and_meta(inputs, label, training=False), num_parallel_calls=AUTOTUNE) # training=False\n","    .batch(BATCH_SIZE)\n","    .map(preprocess_for_model, num_parallel_calls=AUTOTUNE) # Apply preprocessing\n","    .cache()\n","    .prefetch(AUTOTUNE)\n",")\n","\n","# --- FIX: Updated Test Dataset Pipeline ---\n","test_ds = (\n","    # --- Explicitly define (inputs, outputs) structure ---\n","    tf.data.Dataset.from_tensor_slices(((test_paths, test_meta), test_labels))\n","    # --- Update lambda to match new (inputs, label) structure ---\n","    .map(lambda inputs, label: load_image_and_meta(inputs, label, training=False), num_parallel_calls=AUTOTUNE) # training=False\n","    .batch(BATCH_SIZE)\n","    .map(preprocess_for_model, num_parallel_calls=AUTOTUNE) # Apply preprocessing\n","    .cache()\n","    .prefetch(AUTOTUNE)\n",")\n","print(\"Pipelines built successfully.\")\n","\n","# --- 7. Build the Hybrid Model ---\n","print(\"\\nBuilding Hybrid Keras Model...\")\n","\n","# --- Image Branch (DL) ---\n","image_input = Input(shape=IMG_SIZE + (3,), name='image_input')\n","# Give the base model a name so we can find it later\n","base_model = EfficientNetB3(\n","    input_tensor=image_input,\n","    include_top=False,\n","    weights='imagenet',\n","    pooling='max',\n","    name='efficientnetb3' # Name this layer\n",")\n","base_model.trainable = False\n","x_image = base_model.output\n","\n","# --- Metadata Branch (ML) ---\n","meta_input = Input(shape=(num_meta_features,), name='metadata_input')\n","x_meta = Dense(32, activation='relu')(meta_input)\n","x_meta = BatchNormalization()(x_meta)\n","x_meta = Dropout(0.3)(x_meta)\n","\n","# --- Combined Head ---\n","combined = Concatenate()([x_image, x_meta])\n","x = BatchNormalization()(combined)\n","x = Dropout(0.5)(x)\n","x = Dense(512, activation='relu')(x)\n","x = BatchNormalization()(x)\n","x = Dropout(0.5)(x)\n","output = Dense(num_classes, activation='softmax', name='output')(x) # num_classes is now 8\n","\n","# --- Create and Compile Model ---\n","model = Model(inputs=[image_input, meta_input], outputs=output)\n","\n","model.compile(\n","    optimizer=Adam(learning_rate=0.001),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","model.summary()\n","\n","# --- 8. Train the Model (Stage 1: Feature Extraction) ---\n","print(\"\\n--- STAGE 1: Training the classification head ---\")\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True, verbose=1),\n","    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6, verbose=1)\n","]\n","\n","history = model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=30, # Max epochs (as requested)\n","    callbacks=callbacks,\n","    # --- No class_weight needed ---\n",")\n","\n","# Save the best model from Stage 1\n","print(f\"\\nSaving best Stage 1 model to {STAGE_1_SAVE_PATH}...\")\n","model.save(STAGE_1_SAVE_PATH)\n","print(\"âœ… Stage 1 Model saved.\")\n","\n"]},{"cell_type":"code","source":["import lightgbm as lgb\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.metrics import classification_report, accuracy_score\n","import os\n","\n","# --- Re-importing necessary function ---\n","from keras.applications.efficientnet import preprocess_input\n","\n","# --- Constants ---\n","MODEL_SAVE_DIR = '/content/drive/MyDrive/kaggle/working'\n","STAGE_1_SAVE_PATH = os.path.join(MODEL_SAVE_DIR, 'skin_hybrid_stage_1.keras')\n","AUTOTUNE = tf.data.AUTOTUNE\n","BATCH_SIZE = 64  # Increase batch size for faster feature extraction\n","\n","# --- Load Stage 1 Model ---\n","print(\"--- Loading Stage 1 Model ---\")\n","model = tf.keras.models.load_model(STAGE_1_SAVE_PATH, compile=False)\n","\n","# --- Create Feature Extractor ---\n","output_layer_name = 'concatenate_6'  # Change if different in your model\n","feature_extractor = tf.keras.Model(\n","    inputs=model.inputs,\n","    outputs=model.get_layer(output_layer_name).output\n",")\n","print(f\"Feature extractor created ending at layer '{output_layer_name}'\")\n","\n","# --- Preprocessing Helper ---\n","def preprocess_for_buggy_model(inputs, label):\n","    image, meta = inputs\n","    image = preprocess_input(image)  # Must match Stage 1 training\n","    return (image, meta), label\n","\n","# --- Dataset Builder ---\n","def create_extract_dataset(paths, meta, labels):\n","    return (\n","        tf.data.Dataset.from_tensor_slices(((paths, meta), labels))\n","        .map(lambda inputs, label: load_image_and_meta(inputs, label, training=False),\n","             num_parallel_calls=AUTOTUNE)\n","        .batch(BATCH_SIZE)\n","        .map(preprocess_for_buggy_model, num_parallel_calls=AUTOTUNE)\n","        .prefetch(AUTOTUNE)\n","    )\n","\n","# --- Re-create datasets ---\n","ds_extract_train = create_extract_dataset(train_paths, train_meta, train_labels)\n","ds_extract_val   = create_extract_dataset(val_paths, val_meta, val_labels)\n","ds_extract_test  = create_extract_dataset(test_paths, test_meta, test_labels)\n","\n","# --- Extract Features ---\n","print(\"Extracting features...\")\n","train_features = feature_extractor.predict(ds_extract_train)\n","val_features   = feature_extractor.predict(ds_extract_val)\n","test_features  = feature_extractor.predict(ds_extract_test)\n","\n","# Labels\n","train_labels_sparse = train_labels_sparse\n","val_labels_sparse   = val_labels_sparse\n","test_labels_sparse  = test_labels_sparse\n","\n","print(f\"Train features: {train_features.shape}, Test features: {test_features.shape}\")\n","\n","# --- Train LightGBM on GPU ---\n","print(\"--- Training LightGBM (GPU) ---\")\n","\n","lgb_model = lgb.LGBMClassifier(\n","    objective='multiclass',\n","    num_class=num_classes,\n","    metric='multi_logloss',\n","    n_estimators=1000,\n","    learning_rate=0.05,\n","    device='gpu',  # GPU acceleration\n","    random_state=SEED\n",")\n","\n","# Train with early stopping\n","lgb_model.fit(\n","    train_features,\n","    train_labels_sparse,\n","    eval_set=[(val_features, val_labels_sparse)],\n","    eval_metric='multi_logloss',\n","    callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=True)]\n",")\n","\n","# --- Final Evaluation ---\n","print(\"--- Final Evaluation ---\")\n","y_pred = lgb_model.predict(test_features)\n","final_accuracy = accuracy_score(test_labels_sparse, y_pred)\n","print(f\"Test Accuracy: {final_accuracy*100:.2f}%\")\n","print(\"\\nClassification Report:\")\n","print(classification_report(test_labels_sparse, y_pred, target_names=label_encoder.classes_))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WXrHqYxuIFOG","executionInfo":{"status":"ok","timestamp":1762299899354,"user_tz":-330,"elapsed":1243881,"user":{"displayName":"ben Ten","userId":"16566683968766970463"}},"outputId":"701c314c-bdfc-441e-93b1-6ac3fbd66b8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Loading Stage 1 Model ---\n","Feature extractor created ending at layer 'concatenate_6'\n","Extracting features...\n","\u001b[1m350/350\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 558ms/step\n","\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 562ms/step\n","\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 564ms/step\n","Train features: (22400, 1568), Test features: (4800, 1568)\n","--- Training LightGBM (GPU) ---\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 395113\n","[LightGBM] [Info] Number of data points in the train set: 22400, number of used features: 1568\n","[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n","[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n","[LightGBM] [Info] GPU programs have been built\n","[LightGBM] [Info] Size of histogram bin entry: 8\n","[LightGBM] [Info] 1563 dense feature groups (33.41 MB) transferred to GPU in 0.064452 secs. 1 sparse feature groups\n","[LightGBM] [Info] Start training from score -2.079442\n","[LightGBM] [Info] Start training from score -2.079442\n","[LightGBM] [Info] Start training from score -2.079442\n","[LightGBM] [Info] Start training from score -2.079442\n","[LightGBM] [Info] Start training from score -2.079442\n","[LightGBM] [Info] Start training from score -2.079442\n","[LightGBM] [Info] Start training from score -2.079442\n","[LightGBM] [Info] Start training from score -2.079442\n","Training until validation scores don't improve for 100 rounds\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","Early stopping, best iteration is:\n","[375]\tvalid_0's multi_logloss: 0.294566\n","--- Final Evaluation ---\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 89.04%\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","          AK       0.95      0.97      0.96       600\n","         BCC       0.87      0.88      0.87       600\n","         BKL       0.83      0.82      0.83       600\n","          DF       1.00      1.00      1.00       600\n","         MEL       0.71      0.67      0.69       600\n","          NV       0.77      0.79      0.78       600\n","         SCC       0.99      0.99      0.99       600\n","        VASC       1.00      1.00      1.00       600\n","\n","    accuracy                           0.89      4800\n","   macro avg       0.89      0.89      0.89      4800\n","weighted avg       0.89      0.89      0.89      4800\n","\n"]}]},{"cell_type":"code","source":["import joblib\n","import os\n","\n","# --- Define the save directory (Same as your model constants) ---\n","MODEL_SAVE_DIR = '/content/drive/MyDrive/kaggle/working'\n","LGBM_SAVE_PATH = os.path.join(MODEL_SAVE_DIR, 'skin_hybrid_lgbm_model.joblib')\n","\n","# Ensure the directory exists\n","os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n","\n","# --- Save the LightGBM model using joblib ---\n","print(f\"Saving LightGBM model to: {LGBM_SAVE_PATH}...\")\n","joblib.dump(lgb_model, LGBM_SAVE_PATH)\n","print(\"âœ… LightGBM Model saved successfully!\")\n","\n","# --- Verification (Optional) ---\n","# You can add this block to immediately load and verify the saved model\n","print(\"\\nVerifying model load...\")\n","lgb_model_loaded = joblib.load(LGBM_SAVE_PATH)\n","\n","# Test it on the test features to ensure it works\n","y_pred_loaded = lgb_model_loaded.predict(test_features)\n","loaded_accuracy = accuracy_score(test_labels_sparse, y_pred_loaded)\n","\n","# This accuracy should be exactly the same as the one you reported (89.04%)\n","print(f\"Loaded model accuracy verification: {loaded_accuracy*100:.2f}%\")\n","print(\"âœ… Verification complete. The saved model is functional.\")"],"metadata":{"id":"vodxjc4ARYbl","executionInfo":{"status":"ok","timestamp":1762300116089,"user_tz":-330,"elapsed":3457,"user":{"displayName":"ben Ten","userId":"16566683968766970463"}},"outputId":"00fb2c12-02c4-4214-b0d9-2c7f1f3f67ad","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving LightGBM model to: /content/drive/MyDrive/kaggle/working/skin_hybrid_lgbm_model.joblib...\n","âœ… LightGBM Model saved successfully!\n","\n","Verifying model load...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Loaded model accuracy verification: 89.04%\n","âœ… Verification complete. The saved model is functional.\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","import tensorflow as tf\n","import shutil\n","from PIL import Image\n","import joblib # <-- Make sure to import joblib\n","\n","# --- ML/Preprocessing Imports ---\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.utils import resample\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import LabelEncoder\n","\n","# --- Keras Imports ---\n","from keras.models import Model\n","from keras.applications import EfficientNetB3\n","from keras.layers import Input, Dense, Dropout, BatchNormalization, Concatenate\n","from google.colab import drive\n","\n","# --- 0. Mount Google Drive (with check) ---\n","print(\"Mounting Google Drive...\")\n","if not os.path.isdir('/content/drive'):\n","    drive.mount('/content/drive')\n","else:\n","    print(\"Google Drive already mounted.\")\n","\n","# --- 1. Constants and Setup ---\n","ARCHIVE_PATH_ON_DRIVE = '/content/drive/MyDrive/archive.zip'\n","EXTRACT_PATH = '/content/dataset'\n","MODEL_SAVE_DIR = '/content/drive/MyDrive/kaggle/working'\n","os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n","\n","# --- 1b. Unzip Data to Local Disk (FAST I/O) ---\n","if not os.path.isdir(EXTRACT_PATH):\n","    print(f\"Extracting {ARCHIVE_PATH_ON_DRIVE} to local runtime at {EXTRACT_PATH}...\")\n","    shutil.unpack_archive(ARCHIVE_PATH_ON_DRIVE, EXTRACT_PATH)\n","    print(\"âœ… Extraction complete.\")\n","else:\n","    print(f\"âœ… Dataset already extracted at {EXTRACT_PATH}.\")\n","\n","\n","# --- 1c. Update All Paths to Use Local Data ---\n","DATA_ROOT = EXTRACT_PATH\n","METADATA_CSV_PATH = os.path.join(DATA_ROOT, 'ISIC_2019_Training_Metadata.csv')\n","GROUND_TRUTH_CSV_PATH = os.path.join(DATA_ROOT, 'ISIC_2019_Training_GroundTruth.csv')\n","\n","print(f\"Data root set to: {DATA_ROOT}\")\n","\n","# Model parameters\n","SEED = 123\n","TARGET_SAMPLES = 4000\n","\n","# --- 3. Load and Preprocess Hybrid Data ---\n","print(\"\\nLoading and preprocessing hybrid data (CSV + Images)...\")\n","df_meta = pd.read_csv(METADATA_CSV_PATH)\n","df_truth = pd.read_csv(GROUND_TRUTH_CSV_PATH)\n","class_names = [col for col in df_truth.columns if col not in ['image', 'UNK']]\n","num_classes = len(class_names)\n","df_truth['class_name'] = df_truth[class_names + ['UNK']].idxmax(axis=1)\n","df_master = pd.merge(df_meta, df_truth[['image', 'class_name'] + class_names], on='image')\n","df_master = df_master[df_master['class_name'] != 'UNK'].reset_index(drop=True)\n","print(f\"Removed 'UNK' class. Remaining samples: {len(df_master)}\")\n","\n","# --- 3c. Preprocess Metadata ---\n","print(\"\\nPreprocessing metadata (Imputing, Scaling, One-Hot)...\")\n","numeric_cols = ['age_approx']\n","categorical_cols = ['sex', 'anatom_site_general']\n","\n","# Handle Missing Values\n","age_imputer = SimpleImputer(strategy='median')\n","df_master['age_approx'] = age_imputer.fit_transform(df_master[['age_approx']]).ravel()\n","for col in categorical_cols:\n","    cat_imputer = SimpleImputer(strategy='most_frequent')\n","    df_master[col] = cat_imputer.fit_transform(df_master[[col]]).ravel()\n","\n","# Scale Numerical Data\n","# ! This is the 'scaler' we need to save !\n","scaler = StandardScaler()\n","df_master[numeric_cols] = scaler.fit_transform(df_master[numeric_cols])\n","\n","# One-Hot Encode Categorical Data\n","# ! This is the 'encoder' we need to save !\n","encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n","encoded_cats = encoder.fit_transform(df_master[categorical_cols])\n","meta_features = np.concatenate([df_master[numeric_cols].values, encoded_cats], axis=1)\n","num_meta_features = meta_features.shape[1]\n","\n","# ! This print statement will confirm the shape !\n","print(f\"âœ…âœ…âœ… CREATED {num_meta_features} METADATA FEATURES âœ…âœ…âœ…\")\n","# (This should print 11)\n","\n","# --- 4. Manually Balance Dataset (Over/Under-sampling) ---\n","print(f\"\\nBalancing dataset to {TARGET_SAMPLES} samples per class...\")\n","balanced_dfs = []\n","for class_name in class_names:\n","    df_class = df_master[df_master['class_name'] == class_name]\n","    should_replace = len(df_class) < TARGET_SAMPLES\n","    df_balanced_class = resample(df_class,\n","                                 replace=should_replace,\n","                                 n_samples=TARGET_SAMPLES,\n","                                 random_state=SEED)\n","    balanced_dfs.append(df_balanced_class)\n","df_balanced = pd.concat(balanced_dfs)\n","df_balanced = df_balanced.sample(frac=1, random_state=SEED).reset_index(drop=True)\n","print(f\"Balancing complete. New dataset size: {len(df_balanced)}\")\n","\n","# --- 5. Prepare Data for Splitting ---\n","# --- 5a. Prepare Labels ---\n","# ! This is the 'label_encoder' we need to save !\n","label_encoder = LabelEncoder()\n","labels_sparse = label_encoder.fit_transform(df_balanced['class_name'])\n","print(\"Created all preprocessor objects.\")\n","\n","# --- 8.\n","# ---\n","# --- SCRIPT STOPS HERE, NO TRAINING\n","# ---\n","# ---\n","\n","# --- NEW: Save the Preprocessing Objects ---\n","print(\"\\n--- Saving Preprocessing Objects (No Training) ---\")\n","\n","PREPROCESSOR_SAVE_DIR = os.path.join(MODEL_SAVE_DIR, 'preprocessing_objects')\n","os.makedirs(PREPROCESSOR_SAVE_DIR, exist_ok=True)\n","print(f\"Saving preprocessors to: {PREPROCESSOR_SAVE_DIR}\")\n","\n","# 1. Save the age_scaler (from section 3c)\n","scaler_path = os.path.join(PREPROCESSOR_SAVE_DIR, 'age_scaler.pkl')\n","joblib.dump(scaler, scaler_path)\n","print(f\"Saved: {scaler_path}\")\n","\n","# 2. Save the metadata_encoder (from section 3c)\n","meta_encoder_path = os.path.join(PREPROCESSOR_SAVE_DIR, 'metadata_encoder.pkl')\n","joblib.dump(encoder, meta_encoder_path)\n","print(f\"Saved: {meta_encoder_path}\")\n","\n","# 3. Save the label_encoder (from section 5a)\n","label_encoder_path = os.path.join(PREPROCESSOR_SAVE_DIR, 'label_encoder.pkl')\n","joblib.dump(label_encoder, label_encoder_path)\n","print(f\"Saved: {label_encoder_path}\")\n","\n","print(f\"\\nâœ… All preprocessing objects saved successfully to your Google Drive!\")\n","print(\"You can now download this 'preprocessing_objects' folder and use it in your Streamlit app.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u5ELZQaBa_gy","executionInfo":{"status":"ok","timestamp":1762302856682,"user_tz":-330,"elapsed":228206,"user":{"displayName":"ben Ten","userId":"16566683968766970463"}},"outputId":"a7baae70-cee8-4aa0-af03-e74749c4f3fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounting Google Drive...\n","Google Drive already mounted.\n","Extracting /content/drive/MyDrive/archive.zip to local runtime at /content/dataset...\n","âœ… Extraction complete.\n","Data root set to: /content/dataset\n","\n","Loading and preprocessing hybrid data (CSV + Images)...\n","Removed 'UNK' class. Remaining samples: 25331\n","\n","Preprocessing metadata (Imputing, Scaling, One-Hot)...\n","âœ…âœ…âœ… CREATED 11 METADATA FEATURES âœ…âœ…âœ…\n","\n","Balancing dataset to 4000 samples per class...\n","Balancing complete. New dataset size: 32000\n","Created all preprocessor objects.\n","\n","--- Saving Preprocessing Objects (No Training) ---\n","Saving preprocessors to: /content/drive/MyDrive/kaggle/working/preprocessing_objects\n","Saved: /content/drive/MyDrive/kaggle/working/preprocessing_objects/age_scaler.pkl\n","Saved: /content/drive/MyDrive/kaggle/working/preprocessing_objects/metadata_encoder.pkl\n","Saved: /content/drive/MyDrive/kaggle/working/preprocessing_objects/label_encoder.pkl\n","\n","âœ… All preprocessing objects saved successfully to your Google Drive!\n","You can now download this 'preprocessing_objects' folder and use it in your Streamlit app.\n"]}]}]}